{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from model import * \n",
    "from complex_matrix import *\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = False\n",
    "dtype = torch.float32,
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "if USE_GPU == False:\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cuda:0')\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 1\n",
    "def update_upsilon(U_RF, H,V_RF, V_BB, sigma, M, M_RF, K):\n",
    "    upsilon_temp = torch.zeros((K,2,M_RF,M_RF))\n",
    "    for k in range(K):\n",
    "        upsilon_item = torch.zeros((2,M,M))\n",
    "        for j in range(K):\n",
    "            if j==k:\n",
    "                continue\n",
    "            else:\n",
    "                upsilon_item += cmul(cmul(cmul(cmul(cmul(H[k],V_RF),V_BB[j]),conjT(V_BB[j])),conjT(V_RF)),conjT(H[k]))\n",
    "        upsilon_item += (sigma**2) *  mcat(torch.eye(M),torch.zeros((M,M)))\n",
    "        upsilon_temp[k] = cmul(cmul(conjT(U_RF[k]),(upsilon_item)),(U_RF[k]))\n",
    "    return upsilon_temp\n",
    "\n",
    "def update_upsilon_target(U_RF, H, V_RF, V_BB, sigma, M, M_RF, K):\n",
    "    upsilon_temp = np.zeros((K,M_RF,M_RF),complex)\n",
    "    for k in range(K):\n",
    "        upsilon_item = np.zeros((M,M),complex)\n",
    "        for j in range(K):\n",
    "            if j==k:\n",
    "                continue\n",
    "            else:\n",
    "                upsilon_item += H[k].dot(V_RF).dot(V_BB[j]).dot(V_BB[j].conjugate().T).dot(V_RF.conjugate().T).dot(H[k].conjugate().T)\n",
    "        upsilon_item += (sigma**2) * (np.eye(M)+0j*np.eye(M))\n",
    "        upsilon_temp[k] = (U_RF[k].conjugate().T).dot(upsilon_item).dot(U_RF[k])\n",
    "    return upsilon_temp\n",
    "\n",
    "def loss_f(H,V_BB,U_BB,V_RF,U_RF):\n",
    "    loss = target(U_RF, H, V_RF, V_BB, d, P, K)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def produce_data_train():\n",
    "    batch_size = 640\n",
    "    H_set = torch.zeros((batch_size,K,2,M,N))\n",
    "    H = torch.zeros((K,2,M,N))\n",
    "    for i in range(batch_size):\n",
    "        for k in range(K):\n",
    "            H_temp = np.random.randn(M,N)+1j*np.random.randn(M,N)\n",
    "            H[k] = c2m(H_temp)\n",
    "            \n",
    "        H = H.to(dtype=dtype,device=device)\n",
    "        H_set[i] = H[:,:,:,:]\n",
    "    return H_set\n",
    "\n",
    "\n",
    "def produce_data_val():\n",
    "    batch_size = 64\n",
    "\n",
    "    H_set = torch.zeros((batch_size,K,2,M,N))\n",
    "    H = torch.zeros((K,2,M,N))\n",
    "    for i in range(batch_size):\n",
    "        for k in range(K):\n",
    "            H_temp = np.random.randn(M,N)+1j*np.random.randn(M,N)\n",
    "            H[k] = c2m(H_temp)    \n",
    "        H = H.to(dtype=dtype,device=device)\n",
    "        H_set[i] = H[:,:,:,:]\n",
    "    return H_set\n",
    "\n",
    "def Data():\n",
    "    L = 15\n",
    "    parameter = 1     #scale the H\n",
    "    ar_temp = np.zeros((M,1),complex)\n",
    "    at_temp = np.zeros((N,1),complex)\n",
    "    H = np.zeros((M,N),complex)\n",
    "    for l in range(L):\n",
    "        phi_r = np.random.uniform(low=0.0, high=2*np.pi, size=None)\n",
    "        phi_t = np.random.uniform(low=0.0, high=2*np.pi, size=None)\n",
    "        alpha_k_l = np.sqrt(1/2)*(np.random.normal(0,1,1)+1j*np.random.normal(0,1,1))\n",
    "        for m in range(M):\n",
    "            ar_temp[m] = 1/M*(np.cos(np.pi*m*np.sin(phi_r)) + 1j*np.sin(np.pi*m*np.sin(phi_r)))       \n",
    "        for n in range(N):\n",
    "            at_temp[n] = 1/N*(np.cos(np.pi*n*np.sin(phi_t)) + 1j*np.sin(np.pi*n*np.sin(phi_t)))\n",
    "        H = H + parameter * np.sqrt(N*M/L)*alpha_k_l*(np.dot(ar_temp,at_temp.conjugate().T))\n",
    "    return H\n",
    "def target(U_RF, H, V_RF, V_BB, d, P, K):\n",
    "    target = 0\n",
    "    I1 = torch.eye(M_RF)\n",
    "    I2 = torch.zeros((M_RF,M_RF))\n",
    "    I = mcat(I1,I2)\n",
    "    for k in range(K):\n",
    "        target_item = I + cmul(cmul(cmul(cmul(cmul(cmul(cmul(cmul(conjT(U_RF[k,:,:,:]),(H[k,:,:,:])),V_RF[:,:,:]),V_BB[k,:,:,:]),conjT(V_BB[k,:,:,:])),conjT(V_RF[:,:,:])),conjT(H[k,:,:,:])),U_RF[k,:,:,:]),cinv(update_upsilon(U_RF, H,V_RF, V_BB, sigma, M, M_RF, K)[k,:,:,:]))\n",
    "        target -= torch.log(cdet(target_item))\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer,U_BB0,U_RF0,V_BB0,V_RF0,W0,X0,Y0, epochs):\n",
    "    model = model.to(device=device,dtype=dtype) \n",
    "    H_val = produce_data_val()\n",
    "    i = 0\n",
    "    loss = 0\n",
    "    for e in range(epochs):\n",
    "        print(\"epochs %d\"%e) \n",
    "        H_train = produce_data_train()\n",
    "        for p in range(1):\n",
    "            for j in range(640):\n",
    "\n",
    "                model.train()  # put model to training mode\n",
    "                U_BB,U_RF,V_BB,V_RF = DLIAIDNN(H_train[j],U_BB0,U_RF0,V_BB0,V_RF0,W0,X0,Y0)\n",
    "                loss += loss_f(H_train[j],V_BB,U_BB,V_RF,U_RF)/8\n",
    "                if i%8==0: \n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    loss = 0\n",
    "                if i%64 ==0:\n",
    "                    result = 0\n",
    "                    for t in range(64):\n",
    "                        U_BB,U_RF,V_BB,V_RF = DLIAIDNN(H_val[t],U_BB0,U_RF0,V_BB0,V_RF0,W0,X0,Y0)\n",
    "                        # sum_temp = 0\n",
    "                        # for k in range(K):\n",
    "                        #     sum_temp += torch.trace(cmul(conjT(cmul(V_RF,V_BB[k])),cmul(V_RF,V_BB[k]))[0])\n",
    "                      \n",
    "                        #     print(U_RF[0,0,1,1]**2+U_RF[0,1,1,1]**2)\n",
    "                        # print(sum_temp)\n",
    "                        result += loss_f(H_val[t],V_BB,U_BB,V_RF,U_RF)/64\n",
    "                    print(result)\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epochs 0\n",
      "tensor(-20.1578, grad_fn=<AddBackward0>)\n",
      "tensor(-21.7133, grad_fn=<AddBackward0>)\n",
      "tensor(-22.2345, grad_fn=<AddBackward0>)\n",
      "tensor(-22.3306, grad_fn=<AddBackward0>)\n",
      "tensor(-22.6124, grad_fn=<AddBackward0>)\n",
      "tensor(-23.3161, grad_fn=<AddBackward0>)\n",
      "tensor(-23.3431, grad_fn=<AddBackward0>)\n",
      "tensor(-23.9467, grad_fn=<AddBackward0>)\n",
      "tensor(-24.2805, grad_fn=<AddBackward0>)\n",
      "tensor(-24.4564, grad_fn=<AddBackward0>)\n",
      "epochs 1\n",
      "tensor(-24.6822, grad_fn=<AddBackward0>)\n",
      "tensor(-24.7902, grad_fn=<AddBackward0>)\n",
      "tensor(-24.8436, grad_fn=<AddBackward0>)\n",
      "tensor(-25.0232, grad_fn=<AddBackward0>)\n",
      "tensor(-25.0933, grad_fn=<AddBackward0>)\n",
      "tensor(-25.1161, grad_fn=<AddBackward0>)\n",
      "tensor(-25.2503, grad_fn=<AddBackward0>)\n",
      "tensor(-25.3913, grad_fn=<AddBackward0>)\n",
      "tensor(-25.3056, grad_fn=<AddBackward0>)\n",
      "tensor(-25.4361, grad_fn=<AddBackward0>)\n",
      "epochs 2\n",
      "tensor(-25.4803, grad_fn=<AddBackward0>)\n",
      "tensor(-25.5698, grad_fn=<AddBackward0>)\n",
      "tensor(-25.5781, grad_fn=<AddBackward0>)\n",
      "tensor(-25.6186, grad_fn=<AddBackward0>)\n",
      "tensor(-25.6213, grad_fn=<AddBackward0>)\n",
      "tensor(-25.7223, grad_fn=<AddBackward0>)\n",
      "tensor(-25.7735, grad_fn=<AddBackward0>)\n",
      "tensor(-25.7941, grad_fn=<AddBackward0>)\n",
      "tensor(-25.6285, grad_fn=<AddBackward0>)\n",
      "tensor(-25.7861, grad_fn=<AddBackward0>)\n",
      "epochs 3\n",
      "tensor(-25.8944, grad_fn=<AddBackward0>)\n",
      "tensor(-25.8578, grad_fn=<AddBackward0>)\n",
      "tensor(-25.9492, grad_fn=<AddBackward0>)\n",
      "tensor(-26.1205, grad_fn=<AddBackward0>)\n",
      "tensor(-26.1525, grad_fn=<AddBackward0>)\n",
      "tensor(-26.1599, grad_fn=<AddBackward0>)\n",
      "tensor(-26.1814, grad_fn=<AddBackward0>)\n",
      "tensor(-26.1702, grad_fn=<AddBackward0>)\n",
      "tensor(-26.3026, grad_fn=<AddBackward0>)\n",
      "tensor(-26.4144, grad_fn=<AddBackward0>)\n",
      "epochs 4\n",
      "tensor(-26.2930, grad_fn=<AddBackward0>)\n",
      "tensor(-26.4175, grad_fn=<AddBackward0>)\n",
      "tensor(-26.4900, grad_fn=<AddBackward0>)\n",
      "tensor(-26.5045, grad_fn=<AddBackward0>)\n",
      "tensor(-26.4336, grad_fn=<AddBackward0>)\n",
      "tensor(-26.6623, grad_fn=<AddBackward0>)\n",
      "tensor(-26.6577, grad_fn=<AddBackward0>)\n",
      "tensor(-26.7364, grad_fn=<AddBackward0>)\n",
      "tensor(-26.8049, grad_fn=<AddBackward0>)\n",
      "tensor(-26.8407, grad_fn=<AddBackward0>)\n",
      "epochs 5\n",
      "tensor(-26.9320, grad_fn=<AddBackward0>)\n",
      "tensor(-26.9896, grad_fn=<AddBackward0>)\n",
      "tensor(-27.0975, grad_fn=<AddBackward0>)\n",
      "tensor(-27.0325, grad_fn=<AddBackward0>)\n",
      "tensor(-27.0887, grad_fn=<AddBackward0>)\n",
      "tensor(-27.1625, grad_fn=<AddBackward0>)\n",
      "tensor(-27.3067, grad_fn=<AddBackward0>)\n",
      "tensor(-27.3161, grad_fn=<AddBackward0>)\n",
      "tensor(-27.3341, grad_fn=<AddBackward0>)\n",
      "tensor(-27.4189, grad_fn=<AddBackward0>)\n",
      "epochs 6\n",
      "tensor(-27.4596, grad_fn=<AddBackward0>)\n",
      "tensor(-27.5353, grad_fn=<AddBackward0>)\n",
      "tensor(-27.6822, grad_fn=<AddBackward0>)\n",
      "tensor(-27.7516, grad_fn=<AddBackward0>)\n",
      "tensor(-27.7776, grad_fn=<AddBackward0>)\n",
      "tensor(-27.7886, grad_fn=<AddBackward0>)\n",
      "tensor(-27.8224, grad_fn=<AddBackward0>)\n",
      "tensor(-27.8516, grad_fn=<AddBackward0>)\n",
      "tensor(-27.9385, grad_fn=<AddBackward0>)\n",
      "tensor(-27.9752, grad_fn=<AddBackward0>)\n",
      "epochs 7\n",
      "tensor(-28.0620, grad_fn=<AddBackward0>)\n",
      "tensor(-28.1207, grad_fn=<AddBackward0>)\n",
      "tensor(-28.0292, grad_fn=<AddBackward0>)\n",
      "tensor(-28.0026, grad_fn=<AddBackward0>)\n",
      "tensor(-28.1006, grad_fn=<AddBackward0>)\n",
      "tensor(-28.1282, grad_fn=<AddBackward0>)\n",
      "tensor(-28.1747, grad_fn=<AddBackward0>)\n",
      "tensor(-28.2260, grad_fn=<AddBackward0>)\n",
      "tensor(-28.2920, grad_fn=<AddBackward0>)\n",
      "tensor(-28.3387, grad_fn=<AddBackward0>)\n",
      "epochs 8\n",
      "tensor(-28.3699, grad_fn=<AddBackward0>)\n",
      "tensor(-28.4675, grad_fn=<AddBackward0>)\n",
      "tensor(-28.5188, grad_fn=<AddBackward0>)\n",
      "tensor(-28.5481, grad_fn=<AddBackward0>)\n",
      "tensor(-28.6076, grad_fn=<AddBackward0>)\n",
      "tensor(-28.6094, grad_fn=<AddBackward0>)\n",
      "tensor(-28.6112, grad_fn=<AddBackward0>)\n",
      "tensor(-28.5754, grad_fn=<AddBackward0>)\n",
      "tensor(-28.5848, grad_fn=<AddBackward0>)\n",
      "tensor(-28.6076, grad_fn=<AddBackward0>)\n",
      "epochs 9\n",
      "tensor(-28.6962, grad_fn=<AddBackward0>)\n",
      "tensor(-28.7223, grad_fn=<AddBackward0>)\n",
      "tensor(-28.7542, grad_fn=<AddBackward0>)\n",
      "tensor(-28.7646, grad_fn=<AddBackward0>)\n",
      "tensor(-28.7784, grad_fn=<AddBackward0>)\n",
      "tensor(-28.7725, grad_fn=<AddBackward0>)\n",
      "tensor(-28.7759, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8336, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8673, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8849, grad_fn=<AddBackward0>)\n",
      "epochs 10\n",
      "tensor(-28.9404, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9813, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9878, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8629, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8747, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9353, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9073, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8751, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9345, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9651, grad_fn=<AddBackward0>)\n",
      "epochs 11\n",
      "tensor(-28.9270, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9692, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9435, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9883, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0129, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0394, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9340, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9603, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0057, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0814, grad_fn=<AddBackward0>)\n",
      "epochs 12\n",
      "tensor(-29.0483, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0422, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0033, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0248, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0019, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1063, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1712, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2274, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2052, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2654, grad_fn=<AddBackward0>)\n",
      "epochs 13\n",
      "tensor(-29.2417, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3171, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2922, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3068, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3152, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3159, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2874, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3017, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3293, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3226, grad_fn=<AddBackward0>)\n",
      "epochs 14\n",
      "tensor(-29.2742, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2058, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1141, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0882, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1757, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1735, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1892, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1802, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1790, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1972, grad_fn=<AddBackward0>)\n",
      "epochs 15\n",
      "tensor(-29.1949, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2082, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1943, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2029, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2024, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1892, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2028, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2031, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1984, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2278, grad_fn=<AddBackward0>)\n",
      "epochs 16\n",
      "tensor(-29.2651, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2597, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2962, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2838, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3075, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9795, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9583, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1348, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2279, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2433, grad_fn=<AddBackward0>)\n",
      "epochs 17\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1529, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1891, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2670, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3008, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3441, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3235, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2140, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2787, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1997, grad_fn=<AddBackward0>)\n",
      "epochs 18\n",
      "tensor(-29.1750, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2125, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3409, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3301, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3152, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2671, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2974, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2263, grad_fn=<AddBackward0>)\n",
      "tensor(-29.3018, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2879, grad_fn=<AddBackward0>)\n",
      "epochs 19\n",
      "tensor(-29.2941, grad_fn=<AddBackward0>)\n",
      "tensor(-28.3084, grad_fn=<AddBackward0>)\n",
      "tensor(-28.7798, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9183, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1063, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1435, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1479, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0832, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0757, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1654, grad_fn=<AddBackward0>)\n",
      "epochs 20\n",
      "tensor(-29.1876, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2424, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2652, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2749, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2506, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2871, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2723, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2722, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1922, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1636, grad_fn=<AddBackward0>)\n",
      "epochs 21\n",
      "tensor(-29.1371, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1179, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1080, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2010, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1584, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1969, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2249, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1830, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1513, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1487, grad_fn=<AddBackward0>)\n",
      "epochs 22\n",
      "tensor(-29.1539, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1756, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1864, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1545, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1133, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1007, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1085, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0716, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1725, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2131, grad_fn=<AddBackward0>)\n",
      "epochs 23\n",
      "tensor(-29.1997, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2473, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2047, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0496, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0715, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9843, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9872, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9840, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9943, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0977, grad_fn=<AddBackward0>)\n",
      "epochs 24\n",
      "tensor(-29.0862, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0508, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0777, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0130, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0933, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0514, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0061, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0041, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0568, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0591, grad_fn=<AddBackward0>)\n",
      "epochs 25\n",
      "tensor(-29.0752, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0836, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0825, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0501, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0339, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0546, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1039, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1418, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1735, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1572, grad_fn=<AddBackward0>)\n",
      "epochs 26\n",
      "tensor(-29.1342, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1568, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1778, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1757, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2117, grad_fn=<AddBackward0>)\n",
      "tensor(-29.2101, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1765, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1402, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1650, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1976, grad_fn=<AddBackward0>)\n",
      "epochs 27\n",
      "tensor(-29.2382, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1546, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1626, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1027, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0458, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0258, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0305, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0104, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0627, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1013, grad_fn=<AddBackward0>)\n",
      "epochs 28\n",
      "tensor(-29.1235, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1634, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1234, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1178, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0813, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1124, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0823, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0649, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0614, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9792, grad_fn=<AddBackward0>)\n",
      "epochs 29\n",
      "tensor(-29.0679, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9573, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9603, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0175, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9813, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9857, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0470, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0475, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0678, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0759, grad_fn=<AddBackward0>)\n",
      "epochs 30\n",
      "tensor(-29.1206, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0742, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1238, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1719, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1715, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1889, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1557, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0904, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0873, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0771, grad_fn=<AddBackward0>)\n",
      "epochs 31\n",
      "tensor(-29.0517, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0354, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0651, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0224, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0593, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0682, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0914, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0497, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0104, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9574, grad_fn=<AddBackward0>)\n",
      "epochs 32\n",
      "tensor(-28.9167, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8514, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8727, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9123, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8402, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8609, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8978, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9350, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9877, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9973, grad_fn=<AddBackward0>)\n",
      "epochs 33\n",
      "tensor(-28.9864, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0113, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0798, grad_fn=<AddBackward0>)\n",
      "tensor(-27.5248, grad_fn=<AddBackward0>)\n",
      "tensor(-28.6858, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8912, grad_fn=<AddBackward0>)\n",
      "tensor(-28.7393, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8538, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9077, grad_fn=<AddBackward0>)\n",
      "tensor(-28.8509, grad_fn=<AddBackward0>)\n",
      "epochs 34\n",
      "tensor(-28.8313, grad_fn=<AddBackward0>)\n",
      "tensor(-28.9233, grad_fn=<AddBackward0>)\n",
      "tensor(-29.0373, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1512, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1664, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1720, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1645, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1248, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1535, grad_fn=<AddBackward0>)\n",
      "tensor(-29.1194, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f77dc7c3bd1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mDLIAIDNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_RF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM_RF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_in\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDLIAIDNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mtrain_part34\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDLIAIDNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mU_BB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mU_RF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV_BB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV_RF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-64170043163d>\u001b[0m in \u001b[0;36mtrain_part34\u001b[1;34m(model, optimizer, U_BB0, U_RF0, V_BB0, V_RF0, W0, X0, Y0, epochs)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K = 2\n",
    "d = 2\n",
    "M = 2\n",
    "N = 4\n",
    "M_RF = 2\n",
    "N_RF = 4\n",
    "P = 100\n",
    "sigma = 1\n",
    "num_in = 4\n",
    "num_out = 2\n",
    "learning_rate = 0.001\n",
    "temp = torch.randn((N,N_RF))\n",
    "V_RF = torch.zeros(2,N,N_RF)\n",
    "V_RF[0] = torch.cos(temp)\n",
    "V_RF[1] = torch.sin(temp)\n",
    "V_RF = V_RF.to(dtype=dtype,device=device)\n",
    "V_BB = torch.randn((K,2,N_RF,d))\n",
    "\n",
    "temp = torch.randn((K,M,M_RF))\n",
    "U_RF = torch.zeros(K,2,M,M_RF)\n",
    "U_RF[:,0,:,:] = torch.cos(temp)\n",
    "U_RF[:,1,:,:] = torch.sin(temp)\n",
    "U_RF = U_RF.to(dtype=dtype,device=device)\n",
    "\n",
    "V_BB = V_BB.to(dtype=dtype,device=device)\n",
    "sum_temp = 0\n",
    "for k in range(K):\n",
    "    sum_temp += torch.trace(cmul(conjT(cmul(V_RF,V_BB[k])),cmul(V_RF,V_BB[k]))[0])\n",
    "V_BB = V_BB * torch.sqrt(P / sum_temp)\n",
    "\n",
    "W = torch.randn(K,2,d,d)\n",
    "W= W.to(dtype=dtype,device=device)\n",
    "\n",
    "X = torch.randn(K,2,N,d)\n",
    "for k in range(K):\n",
    "    X[k] = cmul(V_RF,V_BB[k])\n",
    "\n",
    "U_BB = torch.randn(K,2,N_RF,d)\n",
    "U_BB = U_BB.to(dtype=dtype,device=device)\n",
    "\n",
    "Y = torch.randn(K,2,N,d)\n",
    "DLIAIDNN = model(K,d,M,N,N_RF,M_RF,P,sigma,num_in,num_out,device)\n",
    "optimizer = torch.optim.Adam(DLIAIDNN.parameters(), lr=learning_rate)\n",
    "train_part34(DLIAIDNN, optimizer,U_BB,U_RF,V_BB,V_RF,W,X,Y, epochs=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
